{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a0eaa4",
   "metadata": {},
   "source": [
    "# Installation of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a71069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\anaconda3\\lib\\site-packages (3.4.18.65)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddf4e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\anaconda3\\lib\\site-packages (3.4.18.65)\n",
      "Requirement already satisfied: pygame in d:\\anaconda3\\lib\\site-packages (2.5.2)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed77e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d00e0567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-storage-blob in d:\\anaconda3\\lib\\site-packages (12.19.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in d:\\anaconda3\\lib\\site-packages (from azure-storage-blob) (1.30.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in d:\\anaconda3\\lib\\site-packages (from azure-storage-blob) (41.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in d:\\anaconda3\\lib\\site-packages (from azure-storage-blob) (4.9.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in d:\\anaconda3\\lib\\site-packages (from azure-storage-blob) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in d:\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in d:\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\anaconda3\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.15.1)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864d55c",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44267c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "DIFFERENT MODES FOR BODY DETECTION\n",
      "Type '1' for Full Body Detection\n",
      "Type '2' for Upper Body Detection\n",
      "Type '3' for Frontal Face Detection\n",
      "Enter Mode: 1\n",
      "Webcam opened: True\n",
      "SET TIME RANGE FOR NIGHT VISION MODE:\n",
      "Enter start hour (0-23): 20\n",
      "Enter start minute (0-59): 0\n",
      "Enter end hour (0-23): 7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pygame\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255\n",
    "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def adjust_brightness(image, brightness):\n",
    "    return cv2.convertScaleAbs(image, alpha=1.0, beta=brightness)\n",
    "\n",
    "def check_person_status(person_id, person_bbox, current_time):\n",
    "    x, y, w, h = person_bbox\n",
    "    person_center = (int(x + w / 2), int(y + h / 2))\n",
    "    \n",
    "    left_of_grey_area_x_start = boundary_zone[0]\n",
    "    left_of_grey_area_x_end = buffer_zone[0]\n",
    "    \n",
    "    in_left_of_grey_area = (left_of_grey_area_x_start < person_center[0] < left_of_grey_area_x_end)\n",
    "    \n",
    "    if person_id not in persons:\n",
    "        persons[person_id] = {\n",
    "            'start_time': current_time,\n",
    "            'in_left_of_grey_area': in_left_of_grey_area,\n",
    "            'loitering': False,  \n",
    "            'out_of_boundary': False,  \n",
    "            'last_time_out_of_boundary': None  \n",
    "        }\n",
    "    else:\n",
    "        person_record = persons[person_id]\n",
    "        if in_left_of_grey_area:\n",
    "            if not person_record['in_left_of_grey_area']:\n",
    "                person_record['start_time'] = current_time\n",
    "            elif current_time - person_record['start_time'] > 5:\n",
    "                pygame.mixer.Sound.play(alert_sound)\n",
    "            person_record['in_left_of_grey_area'] = True\n",
    "        else:\n",
    "            person_record['in_left_of_grey_area'] = False\n",
    "    \n",
    "    boundary_polygon = np.array([\n",
    "        [boundary_zone[0], boundary_zone[1]],\n",
    "        [boundary_zone[0] + boundary_zone[2], boundary_zone[1]],\n",
    "        [boundary_zone[0] + boundary_zone[2], boundary_zone[1] + boundary_zone[3]],\n",
    "        [boundary_zone[0], boundary_zone[1] + boundary_zone[3]]\n",
    "    ], dtype=np.int32)\n",
    "\n",
    "    buffer_polygon = np.array([\n",
    "        [buffer_zone[0], buffer_zone[1]],\n",
    "        [buffer_zone[0] + buffer_zone[2], buffer_zone[1]],\n",
    "        [buffer_zone[0] + buffer_zone[2], buffer_zone[1] + buffer_zone[3]],\n",
    "        [buffer_zone[0], buffer_zone[1] + buffer_zone[3]]\n",
    "    ], dtype=np.int32)\n",
    "    \n",
    "    inside_boundary = cv2.pointPolygonTest(boundary_polygon, person_center, False) >= 0\n",
    "    inside_buffer = cv2.pointPolygonTest(buffer_polygon, person_center, False) >= 0\n",
    "\n",
    "    if person_id not in persons:\n",
    "        persons[person_id] = {\n",
    "            'start_time': current_time, \n",
    "            'loitering': False, \n",
    "            'out_of_boundary': not inside_boundary,\n",
    "            'last_time_out_of_boundary': None \n",
    "        }\n",
    "    else:\n",
    "        if not inside_boundary:\n",
    "            persons[person_id]['out_of_boundary'] = True\n",
    "            persons[person_id]['last_time_out_of_boundary'] = current_time  \n",
    "        else:\n",
    "            persons[person_id]['out_of_boundary'] = False\n",
    "            persons[person_id]['last_time_out_of_boundary'] = None  \n",
    "            \n",
    "    in_left_of_grey_area = person_center[0] > boundary_zone_x and person_center[0] < buffer_zone_x\n",
    "    return in_left_of_grey_area\n",
    "\n",
    "def is_night_time(start_hour, start_minute, end_hour, end_minute):\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    start_time = datetime.datetime(current_datetime.year, current_datetime.month, current_datetime.day, start_hour, start_minute)\n",
    "    end_time = datetime.datetime(current_datetime.year, current_datetime.month, current_datetime.day, end_hour, end_minute)\n",
    "\n",
    "    return start_time <= current_datetime <= end_time or (end_time < start_time and not (end_time < current_datetime < start_time))\n",
    "\n",
    "def get_night_mode_time_range():\n",
    "    while True:\n",
    "        try:\n",
    "            print(\"SET TIME RANGE FOR NIGHT VISION MODE:\")\n",
    "            start_hour = int(input(\"Enter start hour (0-23): \"))\n",
    "            if not 0 <= start_hour <= 23:\n",
    "                raise ValueError(\"Hour must be between 0 and 23.\")\n",
    "            \n",
    "            start_minute = int(input(\"Enter start minute (0-59): \"))\n",
    "            if not 0 <= start_minute <= 59:\n",
    "                raise ValueError(\"Minute must be between 0 and 59.\")\n",
    "            \n",
    "            end_hour = int(input(\"Enter end hour (0-23): \"))\n",
    "            if not 0 <= end_hour <= 23:\n",
    "                raise ValueError(\"Hour must be between 0 and 23.\")\n",
    "            \n",
    "            end_minute = int(input(\"Enter end minute (0-59): \"))\n",
    "            if not 0 <= end_minute <= 59:\n",
    "                raise ValueError(\"Minute must be between 0 and 59.\")\n",
    "            \n",
    "            return start_hour, start_minute, end_hour, end_minute\n",
    "        except ValueError as e:\n",
    "            print(f\"Invalid input: {e}. Please enter valid values.\")\n",
    "            \n",
    "print(\"DIFFERENT MODES FOR BODY DETECTION\")\n",
    "print(\"Type '1' for Full Body Detection\")\n",
    "print(\"Type '2' for Upper Body Detection\")\n",
    "print(\"Type '3' for Frontal Face Detection\")\n",
    "mode = int(input(\"Enter Mode: \"))\n",
    "\n",
    "\n",
    "\n",
    "if mode == 1:\n",
    "    face_cascade_path = \"./haarcascade_fullbody.xml\"\n",
    "elif mode == 2:\n",
    "    face_cascade_path = \"./haarcascade_upperbody.xml\"\n",
    "elif mode == 3:\n",
    "    face_cascade_path = \"./haarcascade_frontalface_default.xml\"\n",
    "else:\n",
    "    print(\"Choose a correct mode\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Initialize Pygame for alert\n",
    "pygame.init()\n",
    "alert_sound = pygame.mixer.Sound('buzzer.wav')\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "# INITIALISE THE WEBCAM HERE\n",
    "\n",
    "cap = cv2.VideoCapture(0) # webcam index is either 1 or 0, pls try both if unsure\n",
    "print(\"Webcam opened:\", cap.isOpened())\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------    \n",
    "# Check and create 'Video footages' folder, if no such folder exists it will be created automatically\n",
    "\n",
    "video_folder = \"Video footages\"  # default folder is Video footages, but feel free to rename\n",
    "if not os.path.exists(video_folder):\n",
    "    os.makedirs(video_folder)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------    \n",
    "    \n",
    "    \n",
    "\n",
    "# Define filename for video saving\n",
    "current_datetime = datetime.datetime.now()\n",
    "formatted_date = current_datetime.strftime(\"%Y%m%d_%H%M%S\")\n",
    "video_filename = f\"{video_folder}/recording_{formatted_date}.avi\"\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "# Adjust the resolution (640, 480) to match your webcam's resolution\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter(video_filename, fourcc, 20.0, (640, 480))\n",
    "    \n",
    "\n",
    "#face_cascade_path = './haarcascade_upperbody-Copy1.xml'\n",
    "face_cascade = cv2.CascadeClassifier(face_cascade_path)\n",
    "\n",
    "# Get night mode time range from user\n",
    "night_range_start_hour, night_range_start_minute, night_range_end_hour, night_range_end_minute = get_night_mode_time_range()\n",
    "\n",
    "boundary_zone = [150, 100, 300, 220]\n",
    "buffer_zone = [boundary_zone[0] + 10, boundary_zone[1] + 10, boundary_zone[2] - 20, boundary_zone[3] - 20]\n",
    "loitering_threshold = 5  # 5 sec\n",
    "\n",
    "persons = {}\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Flag to indicate whether the code block should be executed\n",
    "    execute_code = is_night_time(night_range_start_hour, night_range_start_minute, night_range_end_hour, night_range_end_minute)    \n",
    "        \n",
    "    if execute_code:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        current_datetime = datetime.datetime.now()\n",
    "        formatted_datetime = current_datetime.strftime(\"DATE: %d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "        cv2.putText(frame, formatted_datetime, (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)        \n",
    "        \n",
    "        height, width = frame.shape[:2]\n",
    "\n",
    "        expansion_width = 70\n",
    "\n",
    "        boundary_zone_width = (width // 2) + expansion_width\n",
    "        boundary_zone_height = height\n",
    "        boundary_zone_x = (width // 2) - expansion_width\n",
    "        boundary_zone_y = 0\n",
    "\n",
    "        buffer_zone_width = boundary_zone_width // 2\n",
    "        buffer_zone_height = boundary_zone_height\n",
    "        buffer_zone_x = boundary_zone_x + buffer_zone_width - expansion_width // 2\n",
    "        buffer_zone_y = boundary_zone_y\n",
    "\n",
    "        boundary_zone = [boundary_zone_x, boundary_zone_y, boundary_zone_width, boundary_zone_height]\n",
    "        buffer_zone = [buffer_zone_x, buffer_zone_y, buffer_zone_width, buffer_zone_height]\n",
    "\n",
    "        boundary_polygon = np.array([\n",
    "            [boundary_zone[0], boundary_zone[1]],\n",
    "            [boundary_zone[0] + boundary_zone[2], boundary_zone[1]],\n",
    "            [boundary_zone[0] + boundary_zone[2], boundary_zone[1] + boundary_zone[3]],\n",
    "            [boundary_zone[0], boundary_zone[1] + boundary_zone[3]]\n",
    "        ], np.int32)\n",
    "\n",
    "        buffer_polygon = np.array([\n",
    "            [buffer_zone[0], buffer_zone[1]],\n",
    "            [buffer_zone[0] + buffer_zone[2], buffer_zone[1]],\n",
    "            [buffer_zone[0] + buffer_zone[2], buffer_zone[1] + buffer_zone[3]],\n",
    "            [buffer_zone[0], buffer_zone[1] + buffer_zone[3]]\n",
    "        ], np.int32)\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(image=gray, scaleFactor=1.05, minNeighbors=6, minSize=(20, 20))\n",
    "        current_time = time.time()\n",
    "\n",
    "        any_out_of_boundary = False\n",
    "        boundary_color = (0, 255, 0)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            person_id = (x, y, w, h)\n",
    "            check_person_status(person_id, (x, y, w, h), current_time)\n",
    "\n",
    "            person = persons[person_id]\n",
    "\n",
    "            if person['out_of_boundary']:\n",
    "                box_color = (0, 0, 255)\n",
    "                boundary_color = (0, 0, 255)\n",
    "                if person['last_time_out_of_boundary'] and (current_time - person['last_time_out_of_boundary']) < 1:\n",
    "                    pygame.mixer.Sound.play(alert_sound)\n",
    "            elif person['loitering']:\n",
    "                box_color = (0, 165, 255)\n",
    "                if current_time - person['start_time'] >= loitering_threshold:\n",
    "                    pygame.mixer.Sound.play(alert_sound)\n",
    "            else:\n",
    "                box_color = (255, 0, 0)\n",
    "                person['loitering'] = False  # Reset loitering status\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            person_id = (x, y, w, h)\n",
    "            in_left_of_grey_area = check_person_status(person_id, (x, y, w, h), current_time)\n",
    "\n",
    "            # Determine the color of the detection box based on the person's location\n",
    "            if in_left_of_grey_area:\n",
    "                box_color = (0, 165, 255)  # Orange color in BGR\n",
    "            elif person['out_of_boundary']:\n",
    "                box_color = (0, 0, 255)  # Red color in BGR\n",
    "            else:\n",
    "                box_color = (255, 0, 0)  # Blue color in BGR\n",
    "        \n",
    "        \n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), box_color, 3)\n",
    "            \n",
    "            \n",
    "        cv2.polylines(frame, [boundary_polygon], True, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.polylines(frame, [buffer_polygon], True, (128, 128, 128), 2)\n",
    "\n",
    "        \n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gamma_corrected_frame = adjust_gamma(gray_frame, gamma=1.0)\n",
    "        brightened_frame = adjust_brightness(gamma_corrected_frame, brightness=30)\n",
    "        \n",
    "        \n",
    "        \n",
    "        cv2.imshow('Live Webcam Feed', brightened_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    else:\n",
    "            current_datetime = datetime.datetime.now()\n",
    "            formatted_datetime = current_datetime.strftime(\"DATE: %d/%m/%Y %H:%M:%S\")\n",
    "            cv2.putText(frame, formatted_datetime, (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            height, width = frame.shape[:2]\n",
    "            \n",
    "            expansion_width = 70\n",
    "\n",
    "            boundary_zone_width = (width // 2) + expansion_width\n",
    "            boundary_zone_height = height\n",
    "            boundary_zone_x = (width // 2) - expansion_width\n",
    "            boundary_zone_y = 0\n",
    "\n",
    "            buffer_zone_width = boundary_zone_width // 2\n",
    "            buffer_zone_height = boundary_zone_height\n",
    "            buffer_zone_x = boundary_zone_x + buffer_zone_width - expansion_width // 2\n",
    "            buffer_zone_y = boundary_zone_y\n",
    "\n",
    "            boundary_zone = [boundary_zone_x, boundary_zone_y, boundary_zone_width, boundary_zone_height]\n",
    "            buffer_zone = [buffer_zone_x, buffer_zone_y, buffer_zone_width, buffer_zone_height]\n",
    "\n",
    "            boundary_polygon = np.array([\n",
    "                [boundary_zone[0], boundary_zone[1]],\n",
    "                [boundary_zone[0] + boundary_zone[2], boundary_zone[1]],\n",
    "                [boundary_zone[0] + boundary_zone[2], boundary_zone[1] + boundary_zone[3]],\n",
    "                [boundary_zone[0], boundary_zone[1] + boundary_zone[3]]\n",
    "            ], np.int32)\n",
    "\n",
    "            buffer_polygon = np.array([\n",
    "                [buffer_zone[0], buffer_zone[1]],\n",
    "                [buffer_zone[0] + buffer_zone[2], buffer_zone[1]],\n",
    "                [buffer_zone[0] + buffer_zone[2], buffer_zone[1] + buffer_zone[3]],\n",
    "                [buffer_zone[0], buffer_zone[1] + buffer_zone[3]]\n",
    "            ], np.int32)\n",
    "\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(image=gray, scaleFactor=1.1, minNeighbors=6, minSize=(30, 30))\n",
    "            current_time = time.time()\n",
    "\n",
    "            any_out_of_boundary = False\n",
    "            boundary_color = (0, 255, 0)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                person_id = (x, y, w, h)\n",
    "                check_person_status(person_id, (x, y, w, h), current_time)\n",
    "\n",
    "                person = persons[person_id]\n",
    "\n",
    "                if person['out_of_boundary']:\n",
    "                    box_color = (0, 0, 255)\n",
    "                    boundary_color = (0, 0, 255)\n",
    "                    if person['last_time_out_of_boundary'] and (current_time - person['last_time_out_of_boundary']) < 1:\n",
    "                        pygame.mixer.Sound.play(alert_sound)\n",
    "                elif person['loitering']:\n",
    "                    box_color = (0, 165, 255)\n",
    "                    if current_time - person['start_time'] >= loitering_threshold:\n",
    "                        pygame.mixer.Sound.play(alert_sound)\n",
    "                else:\n",
    "                    box_color = (255, 0, 0)\n",
    "                    person['loitering'] = False  # Reset loitering status\n",
    "\n",
    "                    \n",
    "            for (x, y, w, h) in faces:\n",
    "                person_id = (x, y, w, h)\n",
    "                in_left_of_grey_area = check_person_status(person_id, (x, y, w, h), current_time)\n",
    "\n",
    "                # Determine the color of the detection box based on the person's location\n",
    "                if in_left_of_grey_area:\n",
    "                    box_color = (0, 165, 255)  # Orange color in BGR\n",
    "                elif person['out_of_boundary']:\n",
    "                    box_color = (0, 0, 255)  # Red color in BGR\n",
    "                else:\n",
    "                    box_color = (255, 0, 0)  # Blue color in BGR\n",
    "                    \n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), box_color, 3)\n",
    "\n",
    "            cv2.polylines(frame, [boundary_polygon], True, (0, 255, 0), 2)\n",
    "            cv2.polylines(frame, [buffer_polygon], True, (128, 128, 128), 2)\n",
    "            \n",
    "\n",
    "            cv2.imshow('Live Webcam Feed', frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8ae549",
   "metadata": {},
   "source": [
    "# Azure Blob Storage Service: Send selective cctv footages to Azure Blob Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import os\n",
    "\n",
    "def get_azure_storage_config():\n",
    "    print(\"Enter Azure Storage Configuration:\")\n",
    "    connection_string = input(\"Enter connection string: \")\n",
    "    container_name = input(\"Enter container name: \")\n",
    "    video_file_name = input(\"Enter video file path (eg [./videos/12345678.avi] remove the '.' at the front if this notebook is not in the same directory as the folder 'videos':\")\n",
    "\n",
    "    return connection_string, container_name, video_file_name\n",
    "\n",
    "# Get Azure Storage configuration from the user\n",
    "connection_string, container_name, video_file_name = get_azure_storage_config()\n",
    "\n",
    "# Create the BlobServiceClient object\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "# Get a reference to a container. Does not make a network call.\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# OPTIONAL: Create a new container if it does not exist\n",
    "# Note: This makes a network call.\n",
    "try:\n",
    "    container_client.create_container()\n",
    "except Exception as e:\n",
    "    print(f\"Container might already exist or another error occurred: {e}\")\n",
    "\n",
    "blob_name = os.path.basename(video_file_name)  \n",
    "blob_client = container_client.get_blob_client(blob_name)\n",
    "\n",
    "# Upload the file\n",
    "with open(video_file_name, \"rb\") as data:\n",
    "    blob_client.upload_blob(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
